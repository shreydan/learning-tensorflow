{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "core-learning-algo-linregr.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hiD1-2bdXs0F"
      ],
      "authorship_tag": "ABX9TyNdZ4S1lO1cxGbGrksWh4Hl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreydan/learning-tensorflow/blob/main/core_learning_algo_linregr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VzOIkx26DJu_"
      },
      "source": [
        "## **TensorFlow Core Learning Algorithms - Linear Regression**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu2APBllDOFh"
      },
      "source": [
        "### **Linear Regression**\n",
        "\n",
        "1. most basic\n",
        "2. between axes of n-dimensions, a best fit line is drawn which creates the closest relation between the points of data.\n",
        "3. **correlates linearly**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1cBrYMYGoYB"
      },
      "source": [
        "!pip install -q sklearn"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy-Oln3CGxad"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9CAavk2Htf9"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "### Titanic Model\n",
        "\n",
        "survived, sex, age, n_siblings_spouses, parch, fare, class, deck, embark_to, alone"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee4kRal3U2EN"
      },
      "source": [
        "# loading dataset:\n",
        "\n",
        "# training data\n",
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
        "\n",
        "#testing data\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
        "\n",
        "y_train = dftrain.pop('survived')\n",
        "y_eval = dfeval.pop('survived')\n"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DLVTo-YWd3S"
      },
      "source": [
        "# print one specific data row\n",
        "\n",
        "print(dftrain.loc[0], y_train.loc[0])\n",
        "\n",
        "# get specific column\n",
        "\n",
        "print(dftrain['age'])\n",
        "\n",
        "# statistical analysis of dataframe\n",
        "\n",
        "dftrain.describe()\n",
        "\n",
        "# shape of data frames - (entries, columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiD1-2bdXs0F"
      },
      "source": [
        "### SOME GRAPHS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Id4hEvgXgG2"
      },
      "source": [
        "# age histogram - (age, count)\n",
        "dftrain.age.hist(bins=20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDxIqAMpYlIG"
      },
      "source": [
        "# sex values\n",
        "dftrain['sex'].value_counts().plot(kind='barh')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_KikBJBYoNR"
      },
      "source": [
        "# class values\n",
        "dftrain['class'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S51yqLXoZB4A"
      },
      "source": [
        "# % survival on the basis of sex\n",
        "\n",
        "pd.concat([dftrain, y_train], axis=1).groupby('sex').survived.mean().plot(kind='bar').set_xlabel('% survive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBddq09wZmRc"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1EtV_gTZrFL"
      },
      "source": [
        "### **Training and Testing Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sPr4gVnZ-fL"
      },
      "source": [
        "training data size >> testing_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKPRbdB7aRd3"
      },
      "source": [
        "CATEGORICAL_COLUMNS = ['sex',\n",
        "                       'n_siblings_spouses',\n",
        "                       'parch',\n",
        "                       'class',\n",
        "                       'deck',\n",
        "                       'embark_town',\n",
        "                       'alone']\n",
        "NUMERIC_COLUMNS = ['age','fare']"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1KvgO0Ka0cJ"
      },
      "source": [
        "**categorical data:** data which has non-numeric values.\n",
        "\n",
        "**numberic data:** data which has numeric values.\n",
        "\n",
        "**feature data:** data which is actually fed to the model to train\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2C3lnQ3YbnZd"
      },
      "source": [
        "feature_columns = []\n",
        "\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "    \n",
        "    # get a list of unique values from feature col\n",
        "    vocabulary = dftrain[feature_name].unique()\n",
        "\n",
        "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name,vocabulary))\n",
        "\n",
        "\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAJvUlkSfv3d"
      },
      "source": [
        "### TRAINING PROCESS\n",
        "\n",
        "-> data is always loaded in batches because large number of data can't fit in RAM all at once. Generally in batches of 32\n",
        "\n",
        "\n",
        "-> **EPOCHS:** number of times model sees the same data\n",
        "\n",
        "-> **Overfitting:** model sees the data too many times\n",
        "\n",
        "\n",
        "//// Now to handle all the above things\n",
        "`input_function()` takes all our data, splits into batches of `tf.data.Dataset`, shuffles if mentioned, and sets the number of `epochs` as well.\n",
        "\n",
        "`input_function()` is always wrapped inside a `make_input_function()` which takes all the arguments necessary to do the above stuff\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I4VNucGhwvE"
      },
      "source": [
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=32):\n",
        "  def input_function():\n",
        "      # creates tf dataset\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000) # shuffles\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs) # epochs\n",
        "    return ds # returns the batch\n",
        "  return input_function # returns the function object for use\n",
        "\n",
        "\n",
        "# create an input function for training data\n",
        "train_input_fn = make_input_fn(dftrain, y_train)\n",
        "\n",
        "# create an input function for testing data\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jbfr2X6h2RA"
      },
      "source": [
        "### **Estimator:** an implementation of the core linear classifier algorithm."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCgZ0hyOiBG8"
      },
      "source": [
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6k8ZE2DjGqv"
      },
      "source": [
        "### **Training the estimator model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EXhSMv0jMJX"
      },
      "source": [
        "# pass the train_input_fn function to train it\n",
        "linear_est.train(train_input_fn)\n",
        "clear_output()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QWlqDgZjsBh"
      },
      "source": [
        "### **Testing the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruYhjdwnjwP7"
      },
      "source": [
        "result = linear_est.evaluate(eval_input_fn)\n",
        "clear_output()"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYVRBc7Hj40q"
      },
      "source": [
        "### **Geting result of the testing:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqaM2L_VkISz",
        "outputId": "180c5a80-aafa-43cc-9e49-d3d482e173f2"
      },
      "source": [
        "print(result['accuracy'])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7651515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4liJ8-TCkTaF",
        "outputId": "a874cd31-6d71-4d1b-888e-e87659f61f12"
      },
      "source": [
        "# complete result dict:\n",
        "\n",
        "for col in result:\n",
        "    print(f'{col} : {result[col]}')"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.7651515007019043\n",
            "accuracy_baseline : 0.625\n",
            "auc : 0.8308846354484558\n",
            "auc_precision_recall : 0.7920464873313904\n",
            "average_loss : 0.4723973274230957\n",
            "label/mean : 0.375\n",
            "loss : 0.46124327182769775\n",
            "precision : 0.698924720287323\n",
            "prediction/mean : 0.37945160269737244\n",
            "recall : 0.6565656661987305\n",
            "global_step : 400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QV048ekly0t"
      },
      "source": [
        "### **Predict**\n",
        "\n",
        "wanna predict the probabilities of survival of each passenger.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVtr9GmZmWjy",
        "outputId": "6768fc53-0f9d-48d8-e268-bf10bd80acc9"
      },
      "source": [
        "predictions = list(linear_est.predict(eval_input_fn))\n",
        "clear_output()\n",
        "for i in range(1):  #lets print the first passenger prediction instead of all len(predictions)\n",
        "    print(dfeval.loc[i])\n",
        "    print(f'did they survive: {y_eval.loc[i]}') # actually what happened\n",
        "    print(f\"[not_surviving, surviving] : {predictions[i]['probabilities']}\")\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sex                          male\n",
            "age                            35\n",
            "n_siblings_spouses              0\n",
            "parch                           0\n",
            "fare                         8.05\n",
            "class                       Third\n",
            "deck                      unknown\n",
            "embark_town           Southampton\n",
            "alone                           y\n",
            "Name: 0, dtype: object\n",
            "did they survive: 0\n",
            "[not_surviving, surviving] : [0.9245796 0.0754204]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}